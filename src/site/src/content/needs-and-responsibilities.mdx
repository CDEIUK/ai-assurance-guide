---
title: Needs and Responsibilities for AI Assurance?
---

import CookieBanner from "../components/cookies"

<CookieBanner />

A range of actors including regulators, developers, executives, and frontline users, need to check that AI systems are trustworthy and compliant with regulation, and to demonstrate this to others. However, these actors often have limited information, or lack the appropriate specialist knowledge to check and verify others’ claims about this.

In the diagram below we have categorised three important groups of actors who will benefit from the development of an AI assurance ecosystem: The AI supply chain, AI assurance service providers and, supporting structures for AI assurance.

TODO: add image

The efforts of different actors in this space are both interdependent and complimentary. Building a mature assurance ecosystem will therefore require active and coordinated effort. The actors specified in the are not meant to be exhaustive, but represent the key roles in the emerging AI assurance ecosystem.

This simplified diagram highlights the main roles of these four important groups of actors in the AI assurance ecosystem. However it is important to note that while the primary goal of the ‘supporting structures’ is to set out criteria for trustworthy AI through regulation, technical standards or guidance, these actors can also provide assurance services via advisory, audit and certification functions e.g. the ICO’s Assurance function.

These actors can each play a number of interdependent roles within an assurance ecosystem. The table below illustrates each actor’s role in demonstrating the trustworthiness of AI systems and their own requirements for building trust in AI systems.

TODO: add table
