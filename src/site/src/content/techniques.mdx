---
title: Techniques for assuring AI systems
---

import CookieBanner from "../components/cookies"
import Collapse from "../components/collapse"
import OutboundLink from "../components/outbound-link"

<CookieBanner />

| Technique             | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Impact assessment     | <p>Used to anticipate the effect of a policy/programme on environmental, equality, human rights, data protection, or other outcomes.</p><p>Example: The Canadian government’s Algorithm Impact Assessment (AIA) is a mandatory questionnaire designed for government departments and agencies that determines the impact level of an automated decision-system. </p><p>The tool is composed of 48 risk and 33 mitigation questions. Assessment scores are based on factors including the system design, algorithm, decision type, impact and data.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Impact evaluation     | <p>Similar in origin and practice to impact assessment, but conducted after a program or policy has been implemented in a retrospective manner.</p><p>Example: CAHAI (the Council of Europe’s Committee on AI and Human Rights) are producing an impact assessment for organisations developing, procuring or deploying AI to identify and mitigate the potential impacts of AI systems on human rights, democracy and the rule of law.</p><p>The impact assessment which combines AI impact assessment with human rights due diligence is designed to be iterative, therefore will incorporate impact evaluation in subsequent assessments.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| Risk assessment       | <p>Seeks to identify risks that might be disruptive to the business carrying out the assessment e.g. reputational damage.</p><p>Example: The UK company Holistic AI is a platform service that provides automated risk assessment and assurance for companies deploying AI systems.</p><p>Holistic AI’s risk assessment platform offers a range of tools in this list including bias audit, and performance testing and continuous monitoring to provide assurance across verticals of bias, privacy, explainability and robustness.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| Bias audit            | <p>Focused on assessing the inputs and outputs of algorithmic systems to determine whether there is unfair bias in the outcome of a decision, classification made by the system or input data used in the system.</p><p>Example: Etiq.ai offers a customizable software platform for data scientists, risk, and business managers in the insurance, lending, and technology industry.</p><p>The platform offers testing, monitoring, optimisation and explainability solutions to allow users to identify and mitigate the unintended bias in machine learning algorithms and build services appropriate for a variety of groups in their consumer base.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| Compliance audit      | <p>Involves a review of a company's adherence to internal policies and procedures, or external regulations or legal requirements. Specialised types of compliance audit include:</p><p>System and process audits that can be used to verify that organisational processes and management systems are operating effectively, according to predetermined standards.</p><p>Regulatory inspection is a type of compliance audit, required by regulatory agencies to review an organisation's operations and ensure compliance with applicable laws, rules and regulations.</p><p>Example: ForHumanity have produced a framework for the independent audit of AI Safety in the categories of Bias, Privacy, Ethics, Trust and Cybersecurity.</p><p>The aim of the audit is to build an ‘infrastructure of trust’. To create this infrastructure of trust, ForHumanity have set out five criteria to ensure that rules are auditable:<ol><li>Binary - compliant/non-compliant</li><li>Measurable/unambigious</li><li>Iterated and open source</li><li>Consensus driven</li><li>Implementable</li></ol></p> |
| Certification         | <p>A process where an independent body attests that a product, service, organisation or individual has been tested against, and met, objective standards of quality or performance.</p><p>Example: RAI certification is used by organisations to demonstrate that an AI system has been designed, built, and deployed in line with the five OECD Principles on Artificial Intelligence:<ol><li>Explainability</li><li>Fairness</li><li>Accountability</li><li>Robustness</li><li>Data Quality</li></ol></p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| Conformity assessment | <p>Provides assurance that a product, service or system being supplied meets the expectations specified or claimed, prior to it entering the market. Conformity assessment includes activities such as testing, inspection and certification.</p><p>Example: The Medicines and Healthcare Products Regulatory Agency (MHRA) has developed an extensive work programme to update regulations applying to software and artificial intelligence as a medical device.</p><p>The reforms will offer clear assurance guidance on how to interpret regulatory requirements and how to demonstrate conformity.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| Performance testing   | <p>Used to assess the performance of a system with respect to predetermined quantitative requirements or benchmarks.</p><p>Example: Fiddler’s platform offers continuous ML monitoring and automated AI explainability for an organisation to monitor, observe, and analyse the performance of their AI models.</p><p>The platform enables users to pinpoint data drift, and alerts users when they need to retrain their models.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Formal verification   | <p>Establishes whether a system satisfies some requirements using the formal methods of mathematics.</p><p>Example: Imandra provides what they call ‘reasoning as a service’. Imandra is a general-purpose automated reasoning engine that leverages formal verification methods to offer a suite of tools that can be used to provide insights into algorithm performance and guarantees for a wide range of algorithms.</p><p>Imandra’s automated reasoning and analysis engine aims to mathematically verify algorithm properties and systematically explore and elucidate possible algorithm behaviors.</p>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |

## Understanding the spectrum of assurance techniques

The spectrum of assurance techniques offer different processes for providing assurance, enabling assurance users to have justified trust in a range of subject matter relevant to the trustworthiness of AI systems.

On one end of this spectrum, impact assessments are designed to account for uncertainty, ambiguity and the unobservability of potential future harms. Impact assessments require expertise and subjective judgement to account for these factors, but they enable standardised processes for qualitatively assessing potential impacts. Assurance can be provided against these processes and the mitigation strategies put in place to deal with potential adverse impacts.

Other end of this spectrum, formal verification is appropriate for assessing trustworthiness for subject matters which can be measured objectively and with a high degree of certainty, but is ineffective if the subject matter is ambiguous, subjective or uncertain.

The table below looks at how different assurance techniques interact with the 5 elements of an assurance engagement.
