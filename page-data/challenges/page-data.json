{"componentChunkName":"component---node-modules-rocketseat-gatsby-theme-docs-core-src-templates-docs-query-js","path":"/challenges/","result":{"data":{"mdx":{"id":"fb7409ad-154d-531a-a6ed-c8f5a73743af","excerpt":"A mature ecosystem will require ongoing effort We have deliberately used the word ecosystem to describe the network of roles needed for assurance. These areâ€¦","fields":{"slug":"/challenges/"},"frontmatter":{"title":"Challenges for AI assurance","description":null,"image":null,"disableTableOfContents":null},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Challenges for AI assurance\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(CookieBanner, {\n    mdxType: \"CookieBanner\"\n  }), mdx(\"h2\", {\n    \"id\": \"a-mature-ecosystem-will-require-ongoing-effort\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#a-mature-ecosystem-will-require-ongoing-effort\",\n    \"aria-label\": \"a mature ecosystem will require ongoing effort permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"A mature ecosystem will require ongoing effort\"), mdx(\"p\", null, \"We have deliberately used the word ecosystem to describe the network of roles needed for assurance. These are interdependent roles that co-evolve, and rely on a balance between competing interests between different actors.\"), mdx(\"p\", null, \"There are some fundamental tensions of assurance ecosystems that can be managed, but do not go away even in mature ecosystems, such as gaming, conflicts of interest, the power dynamics behind technical standards making, balancing innovation and risk minimisation, and responsibility for good AI decisions.\"), mdx(\"p\", null, \"TODO: add image\"), mdx(\"p\", null, \"Tension 1 lies between \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"regulators who may want or need specific rules or requirements\"), \" that they can enforce, and the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"government, which may be intentionally hands-off\"), \" when it comes to setting those standards, or setting policy objectives that drive those standards. Governments may be hesitant to set specific rules for two understandable reasons. Firstly, if they set them too prematurely, they might set the bar too low or be informed by popular sentiment rather than by careful consideration. Secondly, there may be aspects of regulation that government feels is beyond the scope of the state. For example, there are certain aspects of codifying fairness which might need to be left to individual judgement.\"), mdx(\"p\", null, \"Tension 2 arises due to different \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"trade-offs between risk minimisation and encouraging innovation.\"), \" Governments, regulators, developers, and executives each face a different balance of the risks and benefits of these technologies, and often have incentives that are in tension. To resolve this, a balanced approach is needed to consider the risks and benefits across the ecosystem. The ideal arrangement is one where assurance acts to give greater confidence to both developers and purchasers of AI systems and enables wider, safer adoption.\"), mdx(\"p\", null, \"Tension 3 concerns \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"accepting responsibility for good AI decisions.\"), \" Developers and executives may have the same goal - for example to have fair and safe outcomes - but each would like the other party to ultimately be accountable. Developers may say that they are creating a tool and it\\u2019s up to executives to use it correctly. Executives may say they are using a tool and it\\u2019s up to developers to make it work well. In practice, both may be responsible, but more guidance will be necessary to resolve this tension. This tension is particularly pertinent in the AI context where executives often procure AI technology rather than building tools in-house.\"), mdx(\"p\", null, \"Tension 4, \\u2018gaming\\u2019 the outcome, might arise if developers and executives offer too much transparency about how the system works, potentially creating a situation where citizens or frontline users can \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"tweak the inputs to achieve certain outcomes,\"), \" thereby \\u2018gaming\\u2019 the system. This might be considered a downside of \", mdx(OutboundLink, {\n    href: \"https://arxiv.org/abs/1708.01870\",\n    mdxType: \"OutboundLink\"\n  }, \"too much transparency\"), \".\"), mdx(\"p\", null, \"Tension 5 might arise where those who deploy algorithms need to communicate trustworthiness with affected individuals, and likewise affected individuals need assurance that an algorithmic system makes good decisions. These parallel goals - one to communicate trustworthiness, and the other to entrust - may lead to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"situations where developers and frontline users offer empty explanations\"), \" and transparency to \", mdx(OutboundLink, {\n    href: \"https://arxiv.org/abs/1708.01870\",\n    mdxType: \"OutboundLink\"\n  }, \"psychologically soothe\"), \", or in a way that may ultimately be meaningless to consumers and citizens.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Because of these fundamental tensions, even mature ecosystems can fail,\"), \" as we have seen with the \", mdx(OutboundLink, {\n    href: \"https://www.bbc.co.uk/news/business-34324772\",\n    mdxType: \"OutboundLink\"\n  }, \"Volkswagen emissions scandal\"), \", where the Environmental Protection Agency found that VW had programmed their cars to display false emissions figures in testing. The \", mdx(OutboundLink, {\n    href: \"https://www.investopedia.com/articles/economics/09/financial-crisis-review.asp\",\n    mdxType: \"OutboundLink\"\n  }, \"2008 financial crisis\"), \" provides a further example, where credit rating agencies falsely gave the highest triple-A ratings to mortgage backed securities, ignoring correlated risk and leaving financial institutions with near-worthless investments in subprime mortgages. Though a well functioning assurance ecosystem makes these the exception rather than the rule, preventing and mitigating these challenges requires vigilance and scrutiny, and cannot be solved by a \\u2018set-and-forget\\u2019 testing regime.\"), mdx(\"p\", null, \"Preventing and mitigating these challenges requires vigilance and scrutiny, and cannot be solved by a \\u2018set-and-forget\\u2019 testing regime. Additional challenges are posed to AI assurance by the autonomous, complex and scalable nature of AI, which make it more difficult to keep track of who is accountable, where they are accountable and what they are accountable for.\"), mdx(\"p\", null, \"Despite the presence of tensions, an assurance ecosystem needs to be built on effective coordination between different roles. An ecosystem that relies too heavily on the role of one player might work for a while, but will be unstable due to the different incentives of the various roles. Whether that is a central regulator or reliance on the self assessed reports of developers, overreliance on one player will fail to reflect the needs and interests of actors across the ecosystem.\"), mdx(\"p\", null, \"If only central regulators are relied on, capacity for assurance will be too low to keep up with demand, hindering innovation. Similarly, If assurance is over-reliant upon the self-assessment of developers, the ecosystem will lack the supporting structures that determine good practice and build trust and trustworthiness.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"It will be important for all actors in AI Assurance to play their part in building a trusted and trustworthy AI assurance ecosystem.\")), mdx(License, {\n    mdxType: \"License\"\n  }));\n}\n;\nMDXContent.isMDXComponent = true;","headings":[{"depth":2,"value":"A mature ecosystem will require ongoing effort"}]}},"pageContext":{"slug":"/challenges/","prev":{"label":"The role of technical standards in AI assurance","link":"/technical-standards"},"next":{"label":"Techniques for assuring AI systems","link":"/techniques"}}}}